{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547b2e76-ca81-4af3-b7b5-be9b71c5657f",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28db960-eaf7-4621-87ce-379476655879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darylramdin/opt/anaconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from corpus import Corpus, CornellMovieCorpus, Vocabulary\n",
    "from rnn import Encoder, Decoder\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import random\n",
    "from torch.utils.data import DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837ad4f-cc3d-44ae-a4b3-fd1ac9dfa6d8",
   "metadata": {},
   "source": [
    "<h2>Parameter Settings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da89873-4a1f-466c-8773-e724b424627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(77)\n",
    "SIZEOF_EMBEDDING = 256\n",
    "NUMBER_OF_EPOCHS = 1\n",
    "PRINT_INTERVAL = 10\n",
    "BATCH_SIZE = 1\n",
    "TEACHER_FORCING = 1\n",
    "TEACHER_FORCING_DECAY = 1e-10\n",
    "PROGRESS_INTERVAL = 100\n",
    "LEARNING_RATE = 1e-03\n",
    "CONVO_MODE = Corpus.FULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b536192-9da1-44a0-8f42-543ed4229f07",
   "metadata": {},
   "source": [
    "<h2>Use the GPU if present</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadd0113-1b64-487c-a2ee-6d2ed50c1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if (torch.cuda.is_available()):\n",
    "   device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefd147-e96b-4aa0-922f-ca1cb8a51824",
   "metadata": {},
   "source": [
    "<h2>Create a Cornell Movie Corpus </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c057d9c-517b-4e05-8236-b812729d0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie lines...\n",
      "Creating vocabulary...\n",
      "Converting conversation line numbers to text...\n",
      "Creating conversation chain\n"
     ]
    }
   ],
   "source": [
    "corpus = CornellMovieCorpus(convo_mode=CONVO_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdee165-0686-4d27-ae09-10a55d8010fc",
   "metadata": {},
   "source": [
    "<h2>Let's look at some data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc7982e-be6e-44cc-b844-af30a8872892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713 movie lines loaded\n",
      "257093 distinct movie lines exist\n",
      "83097 conversations loaded\n"
     ]
    }
   ],
   "source": [
    "lines = list(corpus.movie_lines.items())\n",
    "print(len(lines), \"movie lines loaded\")\n",
    "\n",
    "distinct_lines = [line[1][\"prepped_text\"] for line in lines]\n",
    "print(len(set(distinct_lines)), \"distinct movie lines exist\")\n",
    "\n",
    "print(len(corpus.movie_convos), \"conversations loaded\")                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea16e0-7ecc-43dd-bd45-577127d2c424",
   "metadata": {},
   "source": [
    "<h2>Create Encoders and Decoders</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76806262-be72-4c3a-8c16-9dad85c1e55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(49048, 256)\n",
       "  (relu): ReLU()\n",
       "  (gru): GRU(256, 256, batch_first=True)\n",
       "  (out): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (out2): Linear(in_features=128, out_features=49048, bias=True)\n",
       "  (softmax): LogSoftmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeof_vocab = corpus.vocabulary.len\n",
    "\n",
    "encoder = Encoder(sizeof_vocab, SIZEOF_EMBEDDING)\n",
    "decoder = Decoder(SIZEOF_EMBEDDING, sizeof_vocab)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5351b6-6a04-4b55-bde9-1de7cad34fd8",
   "metadata": {},
   "source": [
    "<h2>Let's setup our trainer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365a2fdb-c6fb-4a55-81e0-0ed62e58f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(),lr=LEARNING_RATE)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataloader = DataLoader(corpus, batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "#Let's get a random exchange pair\n",
    "epoch_loss = 0\n",
    "start_time = datetime.now()\n",
    "training_loss = []\n",
    "total_sequences = 0\n",
    "interval_sequences = 0\n",
    "\n",
    "if corpus.convo_mode==corpus.FULL:\n",
    "    batch_type = \"Conversation\"\n",
    "else:\n",
    "    batch_type = \"Exchange Pair\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a3f48-e3ac-4a59-9b5d-a44e2e47dacb",
   "metadata": {},
   "source": [
    "<h2>Train</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c1dff4-b1e7-4805-9eb1-e5010226720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Number: 100, Number of sequences: 234, Average sequence loss 12.039960, in 2 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Number: \u001b[39m\u001b[38;5;132;01m{0:1d}\u001b[39;00m\u001b[38;5;124m, Number of sequences: \u001b[39m\u001b[38;5;132;01m{1:1d}\u001b[39;00m\u001b[38;5;124m, Average sequence loss \u001b[39m\u001b[38;5;132;01m{2:.6f}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{3:d}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_counter,interval_sequences,interval_loss\u001b[38;5;241m/\u001b[39mPROGRESS_INTERVAL,timediff))\n\u001b[1;32m     95\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 96\u001b[0m \u001b[43minterval_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     98\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    processed_total_batches = 0\n",
    "    batch_counter = 0\n",
    "\n",
    "    interval_loss = 0\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        \n",
    "        teacher_forcing = False\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        # coder_optimizer.zero_grad()\n",
    "\n",
    "        Q_tensors = batch[1][\"Q\"] #shape(batch_size,convo_length,seq_len)\n",
    "        A_tensors= batch[1][\"Q\"] #shape(batch_size,convo_length,seq_len)\n",
    "        \n",
    "        Q_tensors.to(device)\n",
    "        A_tensors.to(device)\n",
    "\n",
    "        Q_tensors = Q_tensors.squeeze(0)\n",
    "        A_tensors = A_tensors.squeeze(0)\n",
    "        \n",
    "        seq_length= A_tensors.shape[1]\n",
    "\n",
    "        interval_sequences+=len(A_tensors)\n",
    "        total_sequences+=interval_sequences\n",
    "\n",
    "        #print(\"Tensor shapes\", Q_tensors.shape, A_tensors.shape)\n",
    "\n",
    "        #Encode the batch\n",
    "        encoder_output, encoder_hidden = encoder(Q_tensors) # encoder_output: (batch_size, max_seq_len, hidden_size), encoder_hidden: (1, batch_size, hidden_size)\n",
    "\n",
    "        # #The decoder accepts an input and the previous hidden start\n",
    "        # At the start, the first input is the SOS token and the\n",
    "        # hidden state is the output of the encoder i.e. context vector\n",
    "\n",
    "        #The first input to the decoder is the SOS token.\n",
    "        #Iterate through the batch of A_tensors and get the first element in each sequence\n",
    "        decoder_input = A_tensors[:, 0].view(-1,1) #decoder_input (batch_size, 1)\n",
    "\n",
    "        #The initial hidden input to the decoder is the last hidden of the encoder.\n",
    "        #For each sequence in the encoder hidden batch, get the last token. encoder_hidden: (batch_size, max_seq_len, hidden_size)\n",
    "        # decoder_hidden = encoder_output[:,-1:,:].squeeze(1) \n",
    "        # decoder_hidden = decoder_hidden.unsqueeze(0) #decoder_hidden  (1, batch_size, sizeof_hidden)\n",
    "        decoder_hidden = encoder_hidden\n",
    "            \n",
    "#         #Get the output from the decoder.\n",
    "#         #decoder_input (batch_size,1), decoder_hidden (1, batch_size, sizeof_hidden)\n",
    "#         decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden) #decoder_output (batch_size, 1, sizeof_vocab), decoder_hidden (batch_size, sizeof_hidden)\n",
    "#         decoder_output = decoer_output.squeeze(1)\n",
    "        \n",
    "#         #calculate the loss by comparing with the ouput with the first non-SOS token in the A tensor\n",
    "#         target = A_tensors[:,1]\n",
    "#         loss = criterion(decoder_output,target)\n",
    "\n",
    "#         #Get the top prediction indices\n",
    "#         decoder_output = decoder_output.topk(k=1, dim=1).indices\n",
    "        \n",
    "#         #  For each batch, we now iterate through the rest of the sequence\n",
    "#         # in each A_tensor decoding outputs and hidden states\n",
    "        \n",
    "        loss = 0\n",
    "        #If we are using teach forcing then the decoder_hidden is the \n",
    "        if random.random() < TEACHER_FORCING: teacher_forcing = True\n",
    "        \n",
    "        for i in range(seq_length-1):\n",
    "            \n",
    "            #if teacher forcing then the target is fed in as the input\n",
    "            if teacher_forcing: decoder_input = A_tensors[:,i+1].view(-1,1)\n",
    "            \n",
    "            #Get the decoder output and hidden state for the\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden) #decoder_output (batch_size, 1, sizeof_vocab), decoder_hidden (batch_size, sizeof_hidden)\n",
    "\n",
    "            decoder_output = decoder_output.squeeze(1)\n",
    "            # calculate the loss by comparing with the tensor of the target\n",
    "            target = A_tensors[:, i+1]\n",
    "            loss += criterion(decoder_output, target)\n",
    "\n",
    "            #Get the top prediction for each batch\n",
    "            decoder_input = decoder_output.topk(k=1, dim=1).indices\n",
    "\n",
    "        convo_loss = loss/corpus.max_seq_length\n",
    "        interval_loss += convo_loss\n",
    "\n",
    "        \n",
    "        TEACHER_FORCING = max(0,TEACHER_FORCING - (TEACHER_FORCING*TEACHER_FORCING_DECAY))\n",
    "\n",
    "        if batch_counter%PROGRESS_INTERVAL == 0 and batch_counter:\n",
    "            #Calculate the average sequence loss over the interval\n",
    "            end_time = datetime.now()\n",
    "            timediff = end_time - start_time\n",
    "            timediff = timediff.seconds\n",
    "            print(batch_type + ' Number: {0:1d}, Number of sequences: {1:1d}, Average sequence loss {2:.6f}, in {3:d} seconds'.format(batch_counter,interval_sequences,interval_loss/PROGRESS_INTERVAL,timediff))\n",
    "            start_time = datetime.now()\n",
    "            interval_loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            interval_loss = 0\n",
    "            interval_sequences = 0\n",
    "\n",
    "        batch_counter+=1\n",
    "        training_loss.append([batch_counter,convo_loss.item()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff2e84-735a-4cdb-8831-dcb3e08d3fad",
   "metadata": {},
   "source": [
    "<h2>Print the results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2395f8-d7c1-4c04-9ca7-268c68a3ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = np.array(training_loss)\n",
    "plt.plot(training_loss[:,0][::1], training_loss[:,1][::1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fe0a4-6fee-453a-ace7-3640f518f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f0f65-8b72-4954-b620-d6fc841c15ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
