{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547b2e76-ca81-4af3-b7b5-be9b71c5657f",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28db960-eaf7-4621-87ce-379476655879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darylramdin/opt/anaconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "import csv\n",
    "import re\n",
    "from corpus import CornellMovieCorpus, Vocabulary\n",
    "from rnn import Encoder, Decoder\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b536192-9da1-44a0-8f42-543ed4229f07",
   "metadata": {},
   "source": [
    "<h2>Use the GPU if present</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadd0113-1b64-487c-a2ee-6d2ed50c1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#Let's do the GPU stuff\n",
    "device = torch.device('mps')\n",
    "if (torch.cuda.is_available()):\n",
    "   device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefd147-e96b-4aa0-922f-ca1cb8a51824",
   "metadata": {},
   "source": [
    "<h2>Create a Cornell Movie Corpus </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c057d9c-517b-4e05-8236-b812729d0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie lines...\n",
      "Creating vocabulary...\n",
      "Converting conversation line numbers to text...\n",
      "Creating exchange pairs\n"
     ]
    }
   ],
   "source": [
    "random.seed(45)\n",
    "\n",
    "corpus = CornellMovieCorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdee165-0686-4d27-ae09-10a55d8010fc",
   "metadata": {},
   "source": [
    "<h2>Let's look at some data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc7982e-be6e-44cc-b844-af30a8872892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713 movie lines loaded\n",
      "257093 distinct movie lines exist\n",
      "83097 conversations loaded\n",
      "\n",
      "Exchanges\n",
      "\n",
      "221616 exchanges created\n",
      "\n",
      " {'Q': {'tokens': 'can we make this quick roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad again', 'indices': [154, 107, 273, 30, 274, 275, 276, 32, 277, 278, 178, 279, 76, 280, 281, 282, 283, 284, 78, 42, 285, 258]}, 'A': {'tokens': 'well i thought we d start with pronunciation if that s okay with you', 'indices': [87, 7, 270, 107, 48, 271, 91, 272, 53, 84, 13, 11, 91, 16]}}\n",
      "\n",
      " {'Q': {'tokens': 'well i thought we d start with pronunciation if that s okay with you', 'indices': [87, 7, 270, 107, 48, 271, 91, 272, 53, 84, 13, 11, 91, 16]}, 'A': {'tokens': 'not the hacking and gagging and spitting part please', 'indices': [5, 42, 265, 32, 266, 32, 267, 268, 269]}}\n",
      "\n",
      " {'Q': {'tokens': 'not the hacking and gagging and spitting part please', 'indices': [5, 42, 265, 32, 266, 32, 267, 268, 269]}, 'A': {'tokens': 'okay then how bout we try out some french cuisine saturday night', 'indices': [11, 70, 21, 259, 107, 260, 90, 261, 199, 262, 263, 264]}}\n",
      "\n",
      " {'Q': {'tokens': 'you re asking me out that s so cute what s your name again', 'indices': [16, 17, 255, 62, 90, 84, 13, 9, 256, 44, 13, 60, 257, 258]}, 'A': {'tokens': 'forget it', 'indices': [198, 147]}}\n",
      "\n",
      " {'Q': {'tokens': 'no no it s my fault we didn t have a proper introduction', 'indices': [23, 23, 147, 13, 37, 251, 107, 252, 34, 103, 127, 253, 254]}, 'A': {'tokens': 'cameron', 'indices': [244]}}\n",
      "219092 distinct exchanges exist\n"
     ]
    }
   ],
   "source": [
    "lines = list(corpus.movie_lines.items())\n",
    "print(len(lines), \"movie lines loaded\")\n",
    "\n",
    "distinct_lines = [line[1][\"prepped_text\"] for line in lines]\n",
    "print(len(set(distinct_lines)), \"distinct movie lines exist\")\n",
    "\n",
    "print(len(corpus.movie_convos), \"conversations loaded\")\n",
    "\n",
    "\n",
    "print(\"\\nExchanges\\n\")\n",
    "print(len(corpus.exchange_pairs), \"exchanges created\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"\\n\",corpus.exchange_pairs[i])\n",
    "\n",
    "distinct_exchange_pairs = [pair[\"Q\"][\"tokens\"] + \" \" + pair[\"A\"][\"tokens\"] for pair in corpus.exchange_pairs]\n",
    "print(len(set(distinct_exchange_pairs)), \"distinct exchanges exist\")                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c60ba-6b27-4312-b169-13e186ece9a7",
   "metadata": {},
   "source": [
    "<h2>Create the vocabulary</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a0ab0d-7fd8-462b-aed4-bcc07a84ad42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': 'dead serious', 'indices': [454, 640]} \n",
      "\n",
      "tensor([  1, 454, 640,   2,   0,   0,   0,   0,   0,   0,   0,   0]) \n",
      "\n",
      "{'tokens': 'you understand this ship cannot be crewed by only two men you ll never make it out of the bay', 'indices': [16, 1140, 30, 1698, 1360, 100, 21156, 636, 224, 162, 490, 16, 347, 88, 273, 147, 90, 39, 42, 2710]} \n",
      "\n",
      "tensor([    1,    16,  1140,    30,  1698,  1360,   100, 21156,   636,   224,\n",
      "          162,     2]) \n",
      "\n",
      "{'tokens': 'yeah', 'indices': [351]} \n",
      "\n",
      "tensor([  1, 351,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0]) \n",
      "\n",
      "{'tokens': 'why do you need that much', 'indices': [239, 4, 16, 19, 84, 207]} \n",
      "\n",
      "tensor([  1, 239,   4,  16,  19,  84, 207,   2,   0,   0,   0,   0]) \n",
      "\n",
      "{'tokens': 'mom', 'indices': [680]} \n",
      "\n",
      "tensor([  1, 680,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0]) \n",
      "\n",
      "{'tokens': 'i ain t lettin go ktil you tell me what s up i m reaching a point where i d kill someone for the nicotine on their fingernails', 'indices': [7, 2752, 34, 13635, 14, 13636, 16, 400, 62, 44, 13, 284, 7, 24, 1590, 127, 213, 188, 7, 48, 1082, 190, 95, 42, 13637, 78, 695, 11033]} \n",
      "\n",
      "tensor([    1,     7,  2752,    34, 13635,    14, 13636,    16,   400,    62,\n",
      "           44,     2]) \n",
      "\n",
      "{'tokens': 'fantasy time girls give it up give it up', 'indices': [3891, 623, 543, 292, 147, 284, 292, 147, 284]} \n",
      "\n",
      "tensor([   1, 3891,  623,  543,  292,  147,  284,  292,  147,  284,    2,    0]) \n",
      "\n",
      "{'tokens': 'lionheart here i m back sorry about the absence i had to do some therapy at the crossbar hotel', 'indices': [29116, 326, 7, 24, 96, 978, 59, 42, 1244, 7, 54, 6, 4, 261, 373, 97, 42, 29133, 1955]} \n",
      "\n",
      "tensor([    1, 29116,   326,     7,    24,    96,   978,    59,    42,  1244,\n",
      "            7,     2]) \n",
      "\n",
      "{'tokens': 'you just go inside homer we don t need no help', 'indices': [16, 28, 14, 1412, 4485, 107, 33, 34, 19, 23, 175]} \n",
      "\n",
      "tensor([   1,   16,   28,   14, 1412, 4485,  107,   33,   34,   19,   23,    2]) \n",
      "\n",
      "{'tokens': 'that s right homer this ain t your business', 'indices': [84, 13, 215, 4485, 30, 2752, 34, 60, 2204]} \n",
      "\n",
      "tensor([   1,   84,   13,  215, 4485,   30, 2752,   34,   60, 2204,    2,    0]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's get a batch of exchanges\n",
    "pairs, batch = corpus.getBatchExchangeTensors(5)\n",
    "\n",
    "for i in range(len(pairs)):\n",
    "    print(pairs[i][\"Q\"],\"\\n\")\n",
    "    print(batch[0][i],\"\\n\")\n",
    "    print(pairs[i][\"A\"],\"\\n\")\n",
    "    print(batch[1][i],\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea16e0-7ecc-43dd-bd45-577127d2c424",
   "metadata": {},
   "source": [
    "<h2>Create Encoders and Decoders</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76806262-be72-4c3a-8c16-9dad85c1e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeof_embedding = 256\n",
    "sizeof_vocab = corpus.vocabulary.len\n",
    "\n",
    "encoder = Encoder(sizeof_vocab, sizeof_embedding)\n",
    "decoder = Decoder(sizeof_embedding, sizeof_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5351b6-6a04-4b55-bde9-1de7cad34fd8",
   "metadata": {},
   "source": [
    "<h2>Let's setup our trainer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365a2fdb-c6fb-4a55-81e0-0ed62e58f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes torch.Size([5, 12]) torch.Size([5, 12])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 256, got 3072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#Encode each word in the input tensor one word a time\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_tensor \u001b[38;5;129;01min\u001b[39;00m Q_tensors:\n\u001b[0;32m---> 37\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#We also keep an array of the outputs\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     encoder_output\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-City,UniversityofLondon/Documents/INM706 - Deep Learning for Sequential Analysis/Coursework/inm706-coursework-daryl-ramdin/rnn.py:21\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input_tensor, hidden_tensor)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,input_tensor,hidden_tensor):\n\u001b[1;32m     20\u001b[0m     output_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_tensor)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#Change the shape to match the input expected by the GRU\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     output_tensor, hidden_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_tensor, hidden_tensor\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:953\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 953\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    956\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:234\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:210\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    208\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    212\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 256, got 3072"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 75000\n",
    "print_interval = 10\n",
    "batch_size = 10\n",
    "teacher_forcing = 0\n",
    "teacher_forcing_decay = 0\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(),lr=1e-03)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(),lr=1e-03)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Let's get a random exchange pair\n",
    "epoch_loss = []\n",
    "start_time = datetime.now()\n",
    "for epoch in range(number_of_epochs):\n",
    "    \n",
    "    pairs, batch = corpus.getBatchExchangeTensors(5)\n",
    "    \n",
    "    Q_tensors = batch[0]\n",
    "    A_tensors= batch[1]\n",
    "    print(\"Tensor shapes\", Q_tensors.shape, A_tensors.shape)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    #input_tensor, target_tensor = corpus.pairToTensor(exchange_pair)\n",
    "    #print(\"Input tensor shape\", input_tensor.shape, \"target\", target_tensor.shape)\n",
    "\n",
    "    #Try this on the encoder\n",
    "    #We need to initialise the hidden state\n",
    "    hidden = torch.zeros(1,corpus.max_seq_length,encoder.sizeof_embedding)\n",
    "\n",
    "    encoder_output = []\n",
    "\n",
    "    #Encode each word in the input tensor one word a time\n",
    "    for input_tensor in Q_tensors:\n",
    "        output, hidden = encoder(input_tensor,hidden)\n",
    "        #We also keep an array of the outputs\n",
    "        encoder_output.append(output)\n",
    "    break\n",
    "    # #The decoder accepts an input and the previous hidden start\n",
    "    # #At the start, the first input is the SOS token and the \n",
    "    # #previous hidden state is the output of the encoder i.e. context vector\n",
    "\n",
    "    int_t = torch.tensor(Vocabulary.SOS_index,dtype=torch.int64)\n",
    "    \n",
    "    hidden = encoder_output[len(encoder_output)-1]\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "\n",
    "    # print(\"Target Tensor\", target_tensor.shape)\n",
    "\n",
    "    decoder_output = []\n",
    "    \n",
    "    for i in range(len(target_tensor)):\n",
    "        if random.random() < teacher_forcing: int_t = target_tensor[i]\n",
    "        \n",
    "        output, hidden = decoder(int_t,hidden)\n",
    "        #print(\"Output\", output.shape, \"Target\", target_tensor[i].shape)\n",
    "        loss += criterion(output,target_tensor[i])\n",
    "        int_t = torch.argmax(output,dim=1)\n",
    "            \n",
    "    if epoch%print_interval == 0: \n",
    "        end_time = datetime.now()\n",
    "        timediff = end_time - start_time\n",
    "        print(\"Epoch\", epoch, \"Loss\", loss.item()/len(target_tensor), \"teacher_forcing\", teacher_forcing, \"in\",timediff.seconds, \"seconds\") \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "    epoch_loss.append([epoch,loss.item()/len(target_tensor)])\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    teacher_forcing = max(0,teacher_forcing - (teacher_forcing_decay * teacher_forcing)) #return 0 if negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb7859-ea97-4265-b462-6441e5b0845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = np.array(epoch_loss)\n",
    "plt.plot(epoch_losses[:,0][::500], epoch_losses[:,1][::500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1dff4-b1e7-4805-9eb1-e5010226720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_losses[:10,0][::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61b480-8d58-4d0e-8056-843beedeb179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
